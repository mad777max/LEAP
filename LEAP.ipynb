{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d188a-fb5f-45b8-8118-33ccbc025213",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8783d453-559d-4e1a-b8c4-321d6484fff5",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dd8083-a543-43ae-bbf2-f6a78b119f9f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# 归一化\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data(X, y, X_mask, y_mask, city_list, item_list):\n",
    "    # 2020 前100个城市\n",
    "    id = np.where(X[::26, 0, 5] == 1)[0][:300]*26\n",
    "    # 存储所有 group 的坐标\n",
    "    ids = []\n",
    "    for start in id:\n",
    "        group_ids = np.arange(start, start + 26)\n",
    "        ids.append(group_ids)\n",
    "    # 将所有坐标合并成一个大数组\n",
    "    train_indices = np.concatenate(ids)\n",
    "\n",
    "    # 2021-2022 和2020其他城市\n",
    "    val_indices = np.setdiff1d(np.arange(X.shape[0]), train_indices)\n",
    "    test_indices = val_indices\n",
    "    \n",
    "    X_train, X_val, X_test = X[train_indices], X[val_indices], X[test_indices]\n",
    "    y_train, y_val, y_test = y[train_indices], y[val_indices], y[test_indices]\n",
    "    X_mask_train, X_mask_val, X_mask_test = X_mask[train_indices], X_mask[val_indices], X_mask[test_indices]\n",
    "    y_mask_train, y_mask_val, y_mask_test = y_mask[train_indices], y_mask[val_indices], y_mask[test_indices]\n",
    "    city_train, city_val, city_test = city_list[train_indices], city_list[val_indices], city_list[test_indices]\n",
    "    item_train, item_val, item_test = item_list[train_indices], item_list[val_indices], item_list[test_indices]\n",
    "    \n",
    "    return (X_train, y_train, X_mask_train, y_mask_train), (X_val, y_val, X_mask_val, y_mask_val), (X_test, y_test, X_mask_test, y_mask_test), (city_train, city_val, city_test), (item_train, item_val, item_test)\n",
    "\n",
    "def normalize_data(X_train, X_val, X_test, y_train, y_val, y_test, columns_to_normalize):\n",
    "    scalers = {}\n",
    "\n",
    "    # Normalize specific columns of X\n",
    "    for col in columns_to_normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train[:, :, col] = scaler.fit_transform(X_train[:, :, col])\n",
    "        X_val[:, :, col] = scaler.transform(X_val[:, :, col])\n",
    "        X_test[:, :, col] = scaler.transform(X_test[:, :, col])\n",
    "        scalers[col] = scaler\n",
    "    \n",
    "    # Normalize the first column of X and y together\n",
    "    first_col_scaler = StandardScaler()\n",
    "    combined_train = np.hstack((X_train[:, :, 0], y_train))\n",
    "    combined_val = np.hstack((X_val[:, :, 0], y_val))\n",
    "    combined_test = np.hstack((X_test[:, :, 0], y_test))\n",
    "    \n",
    "    combined_train = first_col_scaler.fit_transform(combined_train)\n",
    "    combined_val = first_col_scaler.transform(combined_val)\n",
    "    combined_test = first_col_scaler.transform(combined_test)\n",
    "    \n",
    "    X_train[:, :, 0] = combined_train[:, :X_train.shape[1]]\n",
    "    y_train = combined_train[:, X_train.shape[1]:]\n",
    "    X_val[:, :, 0] = combined_val[:, :X_val.shape[1]]\n",
    "    y_val = combined_val[:, X_val.shape[1]:]\n",
    "    X_test[:, :, 0] = combined_test[:, :X_test.shape[1]]\n",
    "    y_test = combined_test[:, X_test.shape[1]:]\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11334fd8-7266-4508-91c3-7086390f719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/unsplit_data.npz', allow_pickle=True)#_deli\n",
    "X = data['X']\n",
    "y = data['y']\n",
    "X_mask = data['X_mask']\n",
    "y_mask = data['y_mask']\n",
    "city_list = data['city_list']\n",
    "item_list = data['item_list']\n",
    "item_to_idx = data['item_to_idx'].item()\n",
    "idx_to_item = data['idx_to_item'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6cc505-d86b-4423-afe5-cb78ba980fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "(X_train, y_train, X_mask_train, y_mask_train), (X_val, y_val, X_mask_val, y_mask_val), (X_test, y_test, X_mask_test, y_mask_test), (city_train, city_val, city_test), (item_train, item_val, item_test) = split_data(X, y, X_mask, y_mask, city_list, item_list)\n",
    "\n",
    "# Normalize data\n",
    "# 2020-2022\n",
    "columns_to_normalize = [1, 2, 3, 4]\n",
    "# # 2023\n",
    "# columns_to_normalize = []\n",
    "(X_train, y_train), (X_val, y_val), (X_test, y_test), scalers = normalize_data(X_train, X_val, X_test, y_train, y_val, y_test, columns_to_normalize)\n",
    "X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape, city_train.shape, city_val.shape, city_test.shape, item_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a160171-29e9-47c6-9c08-9a5e008bd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查GPU可用性\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device: ', device)\n",
    "\n",
    "mode = 'muiti_dim'\n",
    "if mode == 'muiti_dim':\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).to(device)#.squeeze(-1)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "    X_mask_train = torch.tensor(X_mask_train, dtype=torch.float32).to(device)\n",
    "    y_mask_train = torch.tensor(y_mask_train, dtype=torch.float32).to(device)\n",
    "    X_mask_val = torch.tensor(X_mask_val, dtype=torch.float32).to(device)\n",
    "    y_mask_val = torch.tensor(y_mask_val, dtype=torch.float32).to(device)\n",
    "    X_mask_test = torch.tensor(X_mask_test, dtype=torch.float32).to(device)\n",
    "    y_mask_test = torch.tensor(y_mask_test, dtype=torch.float32).to(device)\n",
    "    # city_train = torch.tensor(city_train, dtype=torch.float32).to(device)\n",
    "    # city_val = torch.tensor(city_val, dtype=torch.float32).to(device)\n",
    "    # city_test = torch.tensor(city_test, dtype=torch.float32).to(device)\n",
    "    item_train = torch.tensor(item_train, dtype=torch.long).to(device)\n",
    "    item_val = torch.tensor(item_val, dtype=torch.long).to(device)\n",
    "    item_test = torch.tensor(item_test, dtype=torch.long).to(device)\n",
    "elif mode == '1-dim':\n",
    "    X_train = torch.tensor(X_train, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.float32).to(device)#.squeeze(-1)\n",
    "    X_val = torch.tensor(X_val, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_val = torch.tensor(y_val, dtype=torch.float32).to(device)\n",
    "    X_test = torch.tensor(X_test, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.float32).to(device)\n",
    "    X_mask_train = torch.tensor(X_mask_train, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_mask_train = torch.tensor(y_mask_train, dtype=torch.float32).to(device)\n",
    "    X_mask_val = torch.tensor(X_mask_val, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_mask_val = torch.tensor(y_mask_val, dtype=torch.float32).to(device)\n",
    "    X_mask_test = torch.tensor(X_mask_test, dtype=torch.float32).to(device)[:,:,0].unsqueeze(-1)\n",
    "    y_mask_test = torch.tensor(y_mask_test, dtype=torch.float32).to(device)\n",
    "    # city_train = torch.tensor(city_train, dtype=torch.float32).to(device)\n",
    "    # city_val = torch.tensor(city_val, dtype=torch.float32).to(device)\n",
    "    # city_test = torch.tensor(city_test, dtype=torch.float32).to(device)\n",
    "    item_train = torch.tensor(item_train, dtype=torch.long).to(device)\n",
    "    item_val = torch.tensor(item_val, dtype=torch.long).to(device)\n",
    "    item_test = torch.tensor(item_test, dtype=torch.long).to(device)\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape, X_test.shape, y_test.shape, item_train.shape, X_mask_train.shape)\n",
    "# 城市\n",
    "city_to_idx = {city: idx for idx, city in enumerate(set().union(city_train, city_val, city_test))}\n",
    "idx_to_city = {idx: city for city, idx in city_to_idx.items()}\n",
    "city_train_indices = [city_to_idx[city] for city in city_train]\n",
    "city_train = torch.tensor(city_train_indices).to(device)\n",
    "city_val_indices = [city_to_idx[city] for city in city_val]\n",
    "city_val = torch.tensor(city_val_indices).to(device)\n",
    "city_test_indices = [city_to_idx[city] for city in city_test]\n",
    "city_test = torch.tensor(city_test_indices).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e26fa8-cb51-4b94-b308-79f3e78746d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train, X_mask_train, y_mask_train, city_train, item_train)\n",
    "val_dataset = TensorDataset(X_val, y_val, X_mask_val, y_mask_val, city_val, item_val)\n",
    "test_dataset = TensorDataset(X_test, y_test, X_mask_test, y_mask_test, city_test, item_test)\n",
    "\n",
    "# val_dataset1 = TensorDataset(X_val1, y_val1, X_mask_val1, y_mask_val1, city_val1, item_val1)\n",
    "# val_dataset2 = TensorDataset(X_val2, y_val2, X_mask_val2, y_mask_val2, city_val2, item_val2)\n",
    "\n",
    "import random\n",
    "# 设置随机种子\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "batch_size = 16\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# val_loader1 = DataLoader(val_dataset1, batch_size=batch_size)\n",
    "# val_loader2 = DataLoader(val_dataset2, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6bea9a-be54-4c50-a3ea-aa373b9b67df",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28738be-2d10-4d95-9980-e25a5423d89b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LSTM\n",
    "input_size = 45-8\n",
    "hidden_size = 64\n",
    "output_size = 14\n",
    "epochs = 300\n",
    "\n",
    "param_path = f'./param/pretrain_bs{batch_size}_hs{hidden_size}'\n",
    "\n",
    "# 定义LSTM模型\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.impact = nn.Linear(8, hidden_size//8)\n",
    "        self.fc = nn.Linear(hidden_size+hidden_size//8, output_size)\n",
    "    \n",
    "    def forward(self, x, x_mask):\n",
    "        cols1 = [4] + list(range(8, 15))\n",
    "        cols2 = [i for i in range(45) if i not in cols1]\n",
    "        # 应用输入掩码\n",
    "        x = x * x_mask\n",
    "        x1 = x[:, 0, cols1]\n",
    "        x2 = x[:, :, cols2]\n",
    "        _, (hn, _) = self.lstm(x2) # b*d\n",
    "        x1 = self.impact(x1) # b*d'\n",
    "        out = self.fc(torch.cat((hn[-1], x1), dim=1))\n",
    "        return out, hn[-1], x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f110ac-79c6-4c77-80eb-bd8d92100b9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# TCN\n",
    "class Chomp1d(nn.Module):\n",
    "    def __init__(self, chomp_size):\n",
    "        super(Chomp1d, self).__init__()\n",
    "        self.chomp_size = chomp_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x[:, :, :-self.chomp_size].contiguous()\n",
    "        \n",
    "class TemporalBlock(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs, kernel_size, stride, dilation, padding, dropout=0.2):\n",
    "        super(TemporalBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(n_inputs, n_outputs, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp1 = Chomp1d(padding)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.conv2 = nn.Conv1d(n_outputs, n_outputs, kernel_size,\n",
    "                               stride=stride, padding=padding, dilation=dilation)\n",
    "        self.chomp2 = Chomp1d(padding)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.net = nn.Sequential(self.conv1, self.chomp1, self.relu1, self.dropout1,\n",
    "                                 self.conv2, self.chomp2, self.relu2, self.dropout2)\n",
    "        self.downsample = nn.Conv1d(n_inputs, n_outputs, 1) if n_inputs != n_outputs else None\n",
    "        self.relu = nn.ReLU()\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv1.weight.data.normal_(0, 0.01)\n",
    "        self.conv2.weight.data.normal_(0, 0.01)\n",
    "        if self.downsample is not None:\n",
    "            self.downsample.weight.data.normal_(0, 0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.net(x)\n",
    "        res = x if self.downsample is None else self.downsample(x)\n",
    "        return self.relu(out + res)\n",
    "\n",
    "class TemporalConvNet(nn.Module):\n",
    "    def __init__(self, num_inputs, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TemporalConvNet, self).__init__()\n",
    "        layers = []\n",
    "        num_levels = len(num_channels)\n",
    "        for i in range(num_levels):\n",
    "            dilation_size = 2 ** i\n",
    "            in_channels = num_inputs if i == 0 else num_channels[i-1]\n",
    "            out_channels = num_channels[i]\n",
    "            layers += [TemporalBlock(in_channels, out_channels, kernel_size, stride=1, dilation=dilation_size,\n",
    "                                     padding=(kernel_size-1) * dilation_size, dropout=dropout)]\n",
    "\n",
    "        self.network = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)\n",
    "\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size, num_channels, kernel_size=2, dropout=0.2):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.tcn = TemporalConvNet(input_size, num_channels, kernel_size, dropout)\n",
    "        # self.input = nn.Linear(1, 1)\n",
    "        self.impact = nn.Linear(8, num_channels[-1]//4)\n",
    "        self.fc = nn.Linear(num_channels[-1]+num_channels[-1]//4, output_size)\n",
    "        self.linear = nn.Linear(num_channels[-1], output_size)\n",
    "\n",
    "    def forward(self, x, x_mask):\n",
    "        # x:b*n*d\n",
    "        cols1 = [4] + list(range(8, 15))\n",
    "        # cols2 = [i for i in range(45) if i not in cols1]\n",
    "        cols2 = 0 # [0] + list(range(5, 8)) + list(range(-4, 0)) # list(range(0, 45))\n",
    "        # 应用输入掩码\n",
    "        x = x * x_mask\n",
    "        x = x.permute(0, 2, 1)\n",
    "        x1 = x[:, cols1, 0]\n",
    "        x2 = x[:, cols2, :].unsqueeze(1) # b*d*n\n",
    "        # x2 = self.input(x2.permute(0,2,1)).permute(0,2,1)\n",
    "        \n",
    "        y = self.tcn(x2)[:, :, -1] # b*d(*n)\n",
    "        x1 = self.impact(x1) # b*d'\n",
    "        out = self.fc(torch.cat((y, x1), dim=1))\n",
    "        # out = self.linear(y)\n",
    "\n",
    "        return out, y, x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec320dac-3873-4a4f-94bf-a528ab0fd78d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_size = 1#45-8\n",
    "output_size = 14\n",
    "num_channels = [32, 64, 32]# [64, 64, 64]\n",
    "kernel_size = 2\n",
    "dropout = 0.2\n",
    "epochs = 20\n",
    "param_path = f'./param/pretrain_bs{batch_size}_{num_channels}'\n",
    "deli_param_path = f'./param/pretrain_deli_bs{batch_size}_{num_channels}'\n",
    "# param_path = f'./param/pretrain_deli_bs{batch_size}_{num_channels}'\n",
    "# deli_param_path = f'./param/pretrain_bs{batch_size}_{num_channels}'\n",
    "\n",
    "# 实例化模型\n",
    "pretrained_model = TCNModel(input_size, output_size, num_channels, kernel_size, dropout).to(device)\n",
    "deli_pretrained_model = TCNModel(input_size, output_size, num_channels, kernel_size, dropout).to(device)\n",
    "\n",
    "if not os.path.exists(param_path):\n",
    "    os.makedirs(param_path)\n",
    "if not os.path.exists(deli_param_path):\n",
    "    os.makedirs(deli_param_path)\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(pretrained_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aec0545-229d-4cf0-86e8-b3fe53b34be5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 训练模型\n",
    "best_val_loss = float('inf')\n",
    "for epoch in range(epochs):\n",
    "    pretrained_model.train()\n",
    "    train_loss = 0\n",
    "    for batch_X, batch_y, batch_X_mask, batch_y_mask, _, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _, _ = pretrained_model(batch_X, batch_X_mask)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss = (loss * batch_y_mask).mean()  # 应用输出掩码\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    train_loss /= len(train_loader)\n",
    "    \n",
    "    if (epoch + 1) % 1 == 0:\n",
    "        pretrained_model.eval()\n",
    "        val_loss = 0\n",
    "        mae, mape = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for val_X, val_y, val_X_mask, val_y_mask, _, _ in val_loader:\n",
    "                val_outputs, _, _ = pretrained_model(val_X, val_X_mask)\n",
    "                val_loss_batch = criterion(val_outputs, val_y)\n",
    "                mae_batch = torch.mean(torch.abs(val_outputs - val_y))# * val_y_mask\n",
    "                # mape_batch = torch.abs((val_y - val_outputs) / (val_y + 1e-10))# * val_y_mask\n",
    "                mape_batch = torch.abs((val_y - val_outputs) / val_y)\n",
    "                mape_batch = torch.where(mape_batch > 5, 0, mape_batch)\n",
    "                val_loss += (val_loss_batch * val_y_mask).mean().item()\n",
    "                mae += (mae_batch * val_y_mask).mean().item()\n",
    "                mape += (mape_batch * val_y_mask).mean().item()\n",
    "        val_loss /= len(val_loader)\n",
    "        mae /= len(val_loader)\n",
    "        mape /= len(val_loader)\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, mae: {mae:.4f}, mape: {mape:.4f}')\n",
    "        # 保存 LSTM 模型参数\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save(pretrained_model.state_dict(), deli_param_path+f'/pretrained_model_{epoch+1}.pth')\n",
    "            print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e76653-03c0-41c5-8eff-74fd26845ad0",
   "metadata": {},
   "source": [
    "# similar model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b34afc-84e5-46d7-a6e9-d589b91e022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_file = param_path + '/pretrained_model_16.pth' #1 16\n",
    "\n",
    "pretrain_loader = DataLoader(train_dataset, batch_size=X_train.shape[0])\n",
    "# 加载 LSTM 模型参数\n",
    "pretrained_model.load_state_dict(torch.load(param_file))\n",
    "pretrained_model.eval()\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for batch_X, batch_y, batch_X_mask, batch_y_mask, _, _ in pretrain_loader:\n",
    "    with torch.no_grad():\n",
    "        _, pretrained_embeddings, pretrained_impact = pretrained_model(batch_X, batch_X_mask)\n",
    "print(pretrained_embeddings.shape, pretrained_impact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a9602-1651-497e-bd31-afabcc22380b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embeddings = pretrained_embeddings.reshape(-1, 26, 32)#.reshape(26, -1, 32).transpose(0, 1)\n",
    "pretrained_impact = pretrained_impact.reshape(-1, 26, 8)\n",
    "print(pretrained_embeddings.shape, pretrained_impact.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee9aa04-5b96-4366-b663-8f8bc4e5b5be",
   "metadata": {},
   "source": [
    "### deli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5461c747-e312-48ac-bd6a-0092265aa962",
   "metadata": {},
   "outputs": [],
   "source": [
    "deli_param_file = deli_param_path + '/pretrained_model_2.pth' # 2\n",
    "\n",
    "deli_pretrain_loader = DataLoader(train_dataset, batch_size=X_train.shape[0])\n",
    "# 加载 LSTM 模型参数\n",
    "deli_pretrained_model.load_state_dict(torch.load(deli_param_file))\n",
    "deli_pretrained_model.eval()\n",
    "\n",
    "for param in pretrained_model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for batch_X, batch_y, batch_X_mask, batch_y_mask, _, _ in deli_pretrain_loader:\n",
    "    with torch.no_grad():\n",
    "        _, deli_pretrained_embeddings, deli_pretrained_impact = deli_pretrained_model(batch_X, batch_X_mask)\n",
    "print(deli_pretrained_embeddings.shape, deli_pretrained_impact.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971363ec-f68b-49d3-b725-fe8e61c24004",
   "metadata": {},
   "outputs": [],
   "source": [
    "deli_pretrained_embeddings = deli_pretrained_embeddings.reshape(-1, 26, 32)#.reshape(26, -1, 32).transpose(0, 1)\n",
    "deli_pretrained_impact = deli_pretrained_impact.reshape(-1, 26, 8)\n",
    "print(deli_pretrained_embeddings.shape, deli_pretrained_impact.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c815083-9090-4c6a-af99-72e1737a7da5",
   "metadata": {},
   "source": [
    "### LLM+similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5bcff8-7797-4025-9bc0-70bf756a99fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_embed_tensor = torch.load('./data/embed_tensor.pt').to(device)\n",
    "print(llm_embed_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a5dafc-a33f-4d14-9170-195a24a17bcc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def select_top_k_similar(target_vectors, reference_vectors, top_k=20):\n",
    "    # target_vectors: b*d\n",
    "    # reference_vectors: b*200*d\n",
    "    b, d = target_vectors.shape\n",
    "    \n",
    "    # # 归一化向量\n",
    "    # target_vectors = target_vectors / target_vectors.norm(dim=1, keepdim=True)\n",
    "    # reference_vectors = reference_vectors / reference_vectors.norm(dim=2, keepdim=True)\n",
    "    \n",
    "    # 计算点积\n",
    "    dot_product = torch.bmm(reference_vectors, target_vectors.unsqueeze(2)).squeeze(2)  # b*200\n",
    "\n",
    "    # 计算 A 和 B 的范数\n",
    "    norm_A = torch.norm(target_vectors, dim=1, keepdim=True)  # [b, 1]\n",
    "    norm_B = torch.norm(reference_vectors, dim=2)  # [b, 200]\n",
    "    \n",
    "    # 计算余弦相似度\n",
    "    cosine_similarity = dot_product / (norm_A * norm_B)  # [b, 200]\n",
    "    \n",
    "    # 获取相似度最高的 top_k 个索引\n",
    "    top_k_values, top_k_indices = torch.topk(cosine_similarity, top_k, dim=1)\n",
    "    \n",
    "    return top_k_indices # b*top_k\n",
    "\n",
    "# # 示例用法\n",
    "# b, d = 5, 10  # 例如，5 个目标向量，每个向量 10 维\n",
    "# target_vectors = torch.rand(b, d)\n",
    "# reference_vectors = torch.rand(b, 200, d)\n",
    "\n",
    "# top_k_indices = select_top_k_similar(target_vectors, reference_vectors)\n",
    "# print(top_k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9b9c73-846a-4e08-a015-a9d564b573a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def extract_top_k_vectors(reference_vectors, top_k_indices):\n",
    "    # reference_vectors: b*200*d\n",
    "    # top_k_indices: b*20\n",
    "    b, num_refs, d = reference_vectors.shape\n",
    "    _, top_k = top_k_indices.shape\n",
    "    \n",
    "    # 使用高级索引提取所需的向量\n",
    "    # 通过扩展批次维度来匹配索引\n",
    "    batch_indices = torch.arange(b).unsqueeze(1).expand(-1, top_k)\n",
    "    \n",
    "    # 提取对应的向量\n",
    "    top_k_vectors = reference_vectors[batch_indices, top_k_indices]\n",
    "    \n",
    "    return top_k_vectors # b*top_k*d\n",
    "\n",
    "# # 示例用法\n",
    "# b, num_refs, d = 5, 200, 10\n",
    "# reference_vectors = torch.rand(b, num_refs, d)\n",
    "# top_k_indices = torch.randint(0, num_refs, (b, 20))\n",
    "\n",
    "# top_k_vectors = extract_top_k_vectors(reference_vectors, top_k_indices)\n",
    "# print(top_k_vectors.shape)  # 应输出: torch.Size([5, 20, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e66db1e-41a5-4975-9161-dac7d45d386e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# LLM模型\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "\n",
    "alpha = 0.1\n",
    "epochs = 20\n",
    "hidden_size = num_channels[-1]\n",
    "all_city = city_train[::26]\n",
    "\n",
    "# if not os.path.exists('./logs'):\n",
    "#     os.makedirs('./logs')\n",
    "# # 获取根记录器\n",
    "# logger = logging.getLogger()\n",
    "# # 移除已有的处理器\n",
    "# if logger.hasHandlers():\n",
    "#     logger.handlers.clear()\n",
    "# # 配置日志记录器\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "# logging.basicConfig(\n",
    "#     filename=f'./logs/CLlog_bs{batch_size}_epo{epochs}_{current_time}.log',#\n",
    "#     level=logging.INFO,\n",
    "#     format='%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "# )\n",
    "\n",
    "def contrastive_loss(embedding1, embedding2, temperature=0.5):\n",
    "    # Normalize the embeddings\n",
    "    embedding1 = F.normalize(embedding1, dim=1)\n",
    "    embedding2 = F.normalize(embedding2, dim=1)\n",
    "    \n",
    "    # Compute similarity scores\n",
    "    similarity_matrix = torch.mm(embedding1, embedding2.T) / temperature\n",
    "    \n",
    "    # Create labels (positive samples on diagonal)\n",
    "    labels = torch.arange(similarity_matrix.size(0)).to(similarity_matrix.device)\n",
    "    \n",
    "    # Compute the loss\n",
    "    loss = F.cross_entropy(similarity_matrix, labels)\n",
    "    return loss\n",
    "\n",
    "class SimModel(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(SimModel, self).__init__()\n",
    "        self.x_mlp = nn.Linear(hidden_size, hidden_size)\n",
    "        self.all_xs_mlp = nn.Linear(hidden_size, hidden_size)\n",
    "        self.impact_mlp = nn.Linear(26, 1)\n",
    "        self.post_mlp = nn.Linear(hidden_size//4, hidden_size//4)\n",
    "        self.fc = nn.Linear(hidden_size*2, output_size)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.sim_mlp = nn.Linear(hidden_size+hidden_size//4, hidden_size)#+hidden_size\n",
    "        # self.llm_mlp = nn.Linear(768, hidden_size//4)\n",
    "        self.llm_mlp = nn.Sequential(\n",
    "            nn.Linear(768, hidden_size//2),  # 第一层全连接层\n",
    "            nn.ReLU(),                           # ReLU 激活函数\n",
    "            nn.Linear(hidden_size//2, hidden_size)  # 第二层全连接层\n",
    "        )\n",
    "        self.deli_mlp = nn.Linear(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, deli, x, impact, city, item, all_xs, all_impact, all_city, epoch):\n",
    "        # b*d, b*d, b*d', b, b, 300*26*d, 300*26*d', 300, 1\n",
    "        # pre_attention\n",
    "        x = self.x_mlp(x)\n",
    "        all_xs = self.all_xs_mlp(all_xs)\n",
    "        \n",
    "        scores1 = torch.einsum('bd,mcd->bmc', x, all_xs) / (hidden_size ** 0.5) # b*300*26\n",
    "        weights1 = torch.softmax(scores1, dim=-1)\n",
    "        all_embed = torch.einsum('bmc,mdc->bmd', weights1, all_xs.transpose(1,2)) # b*300*d\n",
    "        # similar\n",
    "        top_k_indices = select_top_k_similar(x, all_embed, top_k=10) # b*k\n",
    "        # reference_city = all_city[top_k_indices] # b*k\n",
    "        # similar_embed = extract_top_k_vectors(all_embed, top_k_indices) # b*k*d\n",
    "        similar_impact = all_impact[top_k_indices] # b*k*26*d'  .unsqueeze(-1).unsqueeze(-1).expand(-1, -1, all_impact.shape[-2], all_impact.shape[-1])\n",
    "        similar_impact = self.impact_mlp(similar_impact.permute(0,1,3,2)).squeeze(-1) # b*k*d'\n",
    "        \n",
    "        # post_attention\n",
    "        similar_impact = self.post_mlp(similar_impact)\n",
    "        scores2 = torch.einsum('bd,bkd->bk', impact, similar_impact) / (hidden_size ** 0.5)\n",
    "        weights2 = torch.softmax(scores2, dim=-1)\n",
    "        sim_embed = torch.einsum('bk,bkd->bd', weights2, similar_impact) # b*d'\n",
    "\n",
    "        # deli = self.deli_mlp(deli)\n",
    "        sim_embed = self.sim_mlp(torch.cat((x, sim_embed), dim=1)) # b*d\n",
    "        # llm_embed\n",
    "        llm_embed = self.llm_mlp(llm_embed_tensor[city, item])\n",
    "        \n",
    "        output = self.fc(torch.cat((sim_embed, llm_embed), dim=1))\n",
    "        # output = self.fc(self.relu(sim_embed))\n",
    "        # output = self.fc(self.relu(torch.cat((sim_embed, deli), dim=1)))\n",
    "        \n",
    "        return sim_embed, llm_embed, output\n",
    "        # return sim_embed, None, output\n",
    "\n",
    "for alpha in [0.1, 0.2, 0.5, 1]: #[0.1]: #\n",
    "    for temperature in [0.2, 0.5, 1]:# [1]:#\n",
    "        print(alpha, temperature, '-'*50)\n",
    "\n",
    "        # 获取根记录器\n",
    "        logger = logging.getLogger()\n",
    "        # 移除已有的处理器\n",
    "        if logger.hasHandlers():\n",
    "            logger.handlers.clear()\n",
    "        logging.basicConfig(\n",
    "            filename=f'./logs/CLlog_alpha{alpha}_tem{temperature}_bs{batch_size}.log',#\n",
    "            level=logging.INFO,\n",
    "            format='%(asctime)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s'\n",
    "        )\n",
    "\n",
    "        # 加载 LSTM 模型参数\n",
    "        pretrained_model.load_state_dict(torch.load(param_file))\n",
    "        pretrained_model.eval()\n",
    "        deli_pretrained_model.load_state_dict(torch.load(deli_param_file))\n",
    "        deli_pretrained_model.eval()\n",
    "        \n",
    "        for param in pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in deli_pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        sim_model = SimModel(hidden_size, output_size).to(device)\n",
    "        optimizer = torch.optim.Adam(sim_model.parameters(), lr=0.001)\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "            sim_model.train()\n",
    "            steps = 0\n",
    "            train_loss = 0\n",
    "            t0 = time.time()\n",
    "            for batch_X, batch_y, batch_X_mask, batch_y_mask, city, item in train_loader:\n",
    "                with torch.no_grad():\n",
    "                    # B*d\n",
    "                    _, embeddings, impact = pretrained_model(batch_X, batch_X_mask)\n",
    "                    _, deli_embeddings, deli_impact = deli_pretrained_model(batch_X, batch_X_mask)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                sim_embed, llm_embed, outputs = sim_model(deli_embeddings, embeddings, impact, city, item, pretrained_embeddings, pretrained_impact, all_city, epoch+1)\n",
    "                loss = criterion(outputs, batch_y)\n",
    "                loss = (loss * batch_y_mask).mean() + contrastive_loss(sim_embed, llm_embed, temperature) * alpha\n",
    "        \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                steps += 1\n",
    "                # print(f'epoch: [{epoch+1}], step: [{steps}], Loss: {loss.item():.4f}')\n",
    "                train_loss += loss.item()\n",
    "            train_loss /= len(train_loader)\n",
    "            t1 = time.time()\n",
    "            # print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, time: {t1-t0}')\n",
    "            # logging.info(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, time: {t1-t0}')\n",
    "                \n",
    "            if (epoch + 1) % 1 == 0:\n",
    "                # t0 = time.time()\n",
    "                sim_model.eval()\n",
    "                val_loss = 0\n",
    "                mae, mape = 0, 0\n",
    "                with torch.no_grad():\n",
    "                    for val_X, val_y, val_X_mask, val_y_mask, val_city, val_item in val_loader:\n",
    "                        _, embeddings, impact = pretrained_model(val_X, val_X_mask)\n",
    "                        _, deli_embeddings, deli_impact = deli_pretrained_model(val_X, val_X_mask)\n",
    "                        _, _, val_outputs = sim_model(deli_embeddings, embeddings, impact, val_city, val_item, pretrained_embeddings, pretrained_impact, all_city, epoch+1)\n",
    "                        val_loss_batch = criterion(val_outputs, val_y)\n",
    "                        steps += 1\n",
    "                        mae_batch = torch.mean(torch.abs(val_outputs - val_y))# * val_y_mask\n",
    "                        # mape_batch = torch.abs((val_y - val_outputs) / (val_y + 1e-10))# * val_y_mask\n",
    "                        mape_batch = torch.abs((val_y - val_outputs) / val_y)\n",
    "                        mape_batch = torch.where(mape_batch > 5, 0, mape_batch)\n",
    "                        val_loss += (val_loss_batch * val_y_mask).mean().item()\n",
    "                        mae += (mae_batch * val_y_mask).mean().item()\n",
    "                        mape += (mape_batch * val_y_mask).mean().item()\n",
    "                val_loss /= len(val_loader)\n",
    "                mae /= len(val_loader)\n",
    "                mape /= len(val_loader)\n",
    "                print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, mae: {mae:.4f}, mape: {mape:.4f}')\n",
    "                logging.info(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, mae: {mae:.4f}, mape: {mape:.4f}')\n",
    "                # 保存 LSTM 模型参数\n",
    "                if val_loss < best_val_loss:\n",
    "                    best_val_loss = val_loss\n",
    "                    if not os.path.exists(f'./param/CLmodel_bs{batch_size}_{epochs}'):\n",
    "                        os.makedirs(f'./param/CLmodel_bs{batch_size}_{epochs}')\n",
    "                    torch.save(sim_model.state_dict(), f'./param/CLmodel_bs{batch_size}_{epochs}/CLmodel_alpha{alpha}_tem{temperature}.pth')\n",
    "                    # print(f'Epoch [{epoch + 1}/{epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, mae: {mae:.4f}, mape: {mape:.4f}')\n",
    "                    print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a51d16a-f140-4809-927f-b19b8e88ffed",
   "metadata": {},
   "source": [
    "# LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1677056f-0c60-4d61-81b7-c6701a42829d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import ujson as json\n",
    "import openai\n",
    "import os\n",
    "\n",
    "# 填写 申请的 apikey 和 erp\n",
    "my_api_key = \"\"\n",
    "my_erp = \"\"\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = my_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f61b61-66dc-49f6-a94b-700d0f968f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_BASE\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07280c2-4393-472b-96c5-442cd2756d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain, ConversationChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import logging\n",
    "import pickle\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f01ca8-b1ea-4844-bd62-d1978d97bc0b",
   "metadata": {},
   "source": [
    "## prompt找相似城市"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05299ba3-068e-44be-9e33-cf7b35b256cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./llmlogs'):\n",
    "    os.makedirs('./llmlogs')\n",
    "# 获取根记录器\n",
    "logger = logging.getLogger()\n",
    "# 移除已有的处理器\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "# 配置日志记录器\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "logging.basicConfig(\n",
    "    filename=f'./llmlogs/similar_city.log',#_bs{batch_size}_epo{epochs}_{current_time}\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "similarcity_dict = {} # {cityidx: [idxs]}\n",
    "for cityidx in city_to_idx.values():\n",
    "    \n",
    "    memory = ConversationBufferMemory()\n",
    "    conversation = ConversationChain(llm=chat_model, memory=memory)\n",
    "    # 定义目标城市和参考城市列表\n",
    "    target_city = f\"<city>({idx_to_city[cityidx]})\"\n",
    "    reference_cities = [idx_to_city[idx.item()] for idx in torch.unique(city_train)]\n",
    "    # 将参考城市列表转换为字符串格式\n",
    "    reference_cities_str = \", \".join([f\"<city>({city})\" for city in reference_cities])\n",
    "    \n",
    "    prompt = f\"有些城市发生了疫情，希望了解这些城市可能的线上单量的变化趋势。我们会给出一个目标城市和一些参考城市，希望你能找到线上单量变化趋势和目标城市最相似的10个参考城市。\\n目标城市的名称如下：{target_city}。参考城市的名单如下：{reference_cities_str}。\\n请从气候信息，地理信息，人口密度，基础设施，经济活动等方面来分析这些城市在发生疫情后，线上订单未来两周可能的变化趋势。请从参考城市中挑选出10个和目标城市最相似的城市，按相似程度的顺序从高到低排列，格式为<city>(城市名)。注意，挑选的城市必须是在参考城市中出现过的。\"\n",
    "    # prompt = f\"目标城市: {target_city}\\n参考城市列表: {reference_cities_str}\\n请根据城市的地理位置、文化、经济、人口等特征进行分析，列出与目标城市最相似的10个城市，仅限于参考城市列表内：\"\n",
    "    response = conversation.run(input=prompt)\n",
    "    # print(\"AI:\", response)\n",
    "    \n",
    "    def validate_and_feedback(response, reference_cities, val_times=0):\n",
    "        # result_cities = [city.strip() for city in response.split(\",\")]\n",
    "        # 正则表达式模式\n",
    "        pattern = r\"<city>\\((.*?)\\)\"\n",
    "        # 查找所有匹配\n",
    "        result_cities = re.findall(pattern, response)\n",
    "        \n",
    "        validated_cities = [city for city in result_cities if city in reference_cities]\n",
    "        missing_cities = [city for city in result_cities if city not in reference_cities]\n",
    "        \n",
    "        if len(validated_cities) < 10 and val_times < 3:\n",
    "            val_times += 1\n",
    "            if len(missing_cities) > 0:\n",
    "                feedback_prompt = f\"你提供的部分城市不在参考城市列表中。缺失的城市: {', '.join(missing_cities)}。请重新生成与目标城市最相似的城市，仅限于参考城市列表内。\"\n",
    "            else:\n",
    "                feedback_prompt = f\"你提供的城市格式有问题，请注意格式必须为<city>(城市名)。请重新生成与目标城市最相似的城市。\"\n",
    "            response = conversation.run(input=feedback_prompt)\n",
    "            # print(\"AI:\", response)\n",
    "            return validate_and_feedback(response, reference_cities, val_times)\n",
    "        return validated_cities\n",
    "    \n",
    "    validated_cities = validate_and_feedback(response, reference_cities)\n",
    "    if len(validated_cities) < 10:\n",
    "        print(f\"与{idx_to_city[cityidx]} 目标城市最相似的{len(validated_cities)}个城市:\", validated_cities)\n",
    "    logging.info(memory.buffer)\n",
    "    similarcity_dict[cityidx] = [city_to_idx[city] for city in validated_cities]\n",
    "\n",
    "# 将字典保存为 Pickle 文件\n",
    "with open('./data/similarcity_dict.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(similarcity_dict, pickle_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ff8917-2250-457e-a795-2d8b5b8cf554",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/similarcity_dict.pkl', 'rb') as pickle_file:\n",
    "    similarcity_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a5bea1-45d0-43ab-abdb-c08c0ed71444",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarcity_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725f94d1-d2bc-48ea-927c-a03fd9802ee3",
   "metadata": {},
   "source": [
    "## prompt分析可能趋势"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82245822-6b8b-46d1-b696-4fff5c63f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_dict = {} # {(city, item): num}\n",
    "train_dict = {(city_train[i].item(), i%26): torch.cat((X_train[i, :, 0], y_train[i, :])).cpu() for i in range(X_train.shape[0])}\n",
    "val_dict = {(city_val[i].item(), i%26): torch.cat((X_val[i, :, 0], y_val[i, :])).cpu() for i in range(X_val.shape[0])}\n",
    "num_dict = {**train_dict, **val_dict}\n",
    "# 将字典保存为 Pickle 文件\n",
    "with open('./data/num_dict.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(num_dict, pickle_file)\n",
    "len(num_dict)/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bb9b4-e142-4a73-9cc7-f2ed376b1969",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open('./data/num_dict.pkl', 'rb') as pickle_file:\n",
    "    num_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bbd0c9-5202-4791-86ff-da180c08fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT提取文本嵌入\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "def text_embed(text):\n",
    "    # 加载预训练的BERT模型和分词器\n",
    "    #t1 = time.time()\n",
    "    tokenizer = BertTokenizer.from_pretrained('./local-bert-base-uncased') #'bert-base-uncased'\n",
    "    #t2 = time.time()\n",
    "    model = BertModel.from_pretrained('./local-bert-base-uncased').to(device)\n",
    "    #t3 = time.time()\n",
    "\n",
    "    # 将文本编码为输入ID和注意力掩码\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    inputs = {key: value.to(device) for key, value in inputs.items()}\n",
    "    #t4 = time.time()\n",
    "    \n",
    "    # 获取BERT模型的输出\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # 获取最后一个隐藏层的输出\n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    # 通常，我们可以使用CLS token的嵌入作为句子的表示\n",
    "    sentence_embedding = last_hidden_states[:, 0, :].squeeze()\n",
    "    #t5 = time.time()\n",
    "    #print(t5-t4, t4-t3, t3-t2, t2-t1)\n",
    "    return sentence_embedding\n",
    "    \n",
    "# # 输入文本\n",
    "# text = [\"This is an example sentence.\", \"agrret\"]\n",
    "# sentence_embedding = text_embed(text)\n",
    "# print(sentence_embedding[0].shape) # 768"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aeb681-96d9-4bf8-956c-eed1619a3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_summary(text):\n",
    "    # 查找 \"@总结:\" 的起始位置\n",
    "    start_index = text.find(\"@总结：\")\n",
    "    \n",
    "    # 如果找到了 \"@总结:\"\n",
    "    if start_index != -1:\n",
    "        # 加上 \"@总结:\" 的长度，计算内容的起始位置\n",
    "        content_start = start_index + len(\"@总结：\")\n",
    "        # 提取并返回从该位置开始的内容\n",
    "        return text[content_start:].strip()\n",
    "    else:\n",
    "        # 如果没有找到 \"@总结:\"，返回默认值\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffde9f4-3d4e-42b3-bd14-234544e1c109",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def normalize_tensor(tensor):\n",
    "    # 使用 torch 的功能计算最小值和最大值\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    \n",
    "    # 避免除以零\n",
    "    if max_val == min_val:\n",
    "        return torch.zeros_like(tensor)\n",
    "    \n",
    "    # 使用广播机制进行归一化\n",
    "    normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    return normalized_tensor\n",
    "\n",
    "# 对字典中的每个张量进行归一化\n",
    "num_dict = {key: normalize_tensor(tensor) for key, tensor in num_dict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f91f13e-da13-45ae-859e-ac4707288597",
   "metadata": {},
   "source": [
    "### 同步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116466f0-d747-4efb-be91-1a3eb5ce5f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import time\n",
    "from transformers import logging as transformers_logging\n",
    "import warnings\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 设置transformers的日志级别为ERROR\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "if not os.path.exists('./llmlogs'):\n",
    "    os.makedirs('./llmlogs')\n",
    "# 获取根记录器\n",
    "logger = logging.getLogger()\n",
    "# 移除已有的处理器\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "# 配置日志记录器\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "logging.basicConfig(\n",
    "    filename=f'./llmlogs/response_dict.log',#_bs{batch_size}_epo{epochs}_{current_time}\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "embed_dict = {}\n",
    "response_dict = {}\n",
    "\n",
    "for cityidx in city_to_idx.values(): # [1]:\n",
    "    t1 = time.time()\n",
    "    for item in range(26): # [0]:\n",
    "        cityidxlist = similarcity_dict[cityidx]\n",
    "        citynumlist = [f\"{idx_to_city[idx]}: 封控前单量：{[round(num, 4) for num in num_dict[(idx, item)][:14].numpy().tolist()]}，封控后单量：{[round(num, 4) for num in num_dict[(idx, item)][14:].numpy().tolist()]}\" for idx in cityidxlist]\n",
    "        citynumstr = \"。\".join(citynumlist)\n",
    "\n",
    "        memory = ConversationBufferMemory()\n",
    "        conversation = ConversationChain(llm=chat_model, memory=memory)\n",
    "\n",
    "        prompt = f\"有些城市发生了疫情，城市封控前后14天的{idx_to_item[item]}类商品的销量（经过了归一化）如下。{citynumstr}。已知{idx_to_city[cityidx]}和上述城市的销量变化相似，请分析{idx_to_city[cityidx]}在封控之后14天内销量的可能变化趋势。给出分析和总结，格式为@分析：（分析内容）@总结：（总结内容）。总结部分仅给出上升下降趋势，幅度，时间，如何波动等销量变化信息，不要提及其他城市，尽量简洁清晰。\"\n",
    "        \n",
    "        response = conversation.run(input=prompt)\n",
    "        logging.info(f\"{cityidx}, {item} \\n{prompt} \\n\\n{response} \\n\")\n",
    "        # sentence_embedding = text_embed(extract_summary(response))\n",
    "        # embed_dict[(cityidx, item)] = sentence_embedding\n",
    "        response_dict[(cityidx, item)] = response\n",
    "        # print(sentence_embedding)\n",
    "    t2 = time.time()\n",
    "    print(cityidx, idx_to_city[cityidx], t2-t1)\n",
    "\n",
    "\n",
    "with open('./data/response_dict.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(response_dict, pickle_file)\n",
    "    \n",
    "# 将字典保存为 Pickle 文件\n",
    "# with open('./data/embed_dict.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(embed_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd56d70c-22f3-4a14-a5e9-769ce9125265",
   "metadata": {},
   "source": [
    "### 异步调用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ee048d-34ae-4726-9205-022ca0c028a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatMessagePromptTemplate\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "import re\n",
    "\n",
    "# 允许在 Jupyter Notebook 中嵌套事件循环\n",
    "nest_asyncio.apply()\n",
    "        \n",
    "async def async_LLM_similar(cityidx, item_list, target_city):\n",
    "    prompt_s1_sys = \"你是一个经济分析师。\"\n",
    "    prompt_s1_user = \"\"\"\n",
    "    有些城市发生了疫情，城市封控前后14天的{item}类商品的销量（经过了归一化）如下。{citynumstr}。已知{target_city}和上述城市的销量变化相似，请分析{target_city}在封控之后14天内销量的可能变化趋势。给出分析和总结，格式为@分析：（分析内容）@总结：（总结内容）。总结部分仅给出上升下降趋势，幅度，时间，如何波动等销量变化信息，不要提及其他城市，尽量简洁清晰。\n",
    "    \"\"\"\n",
    "    \n",
    "    prompt_s1_sys = ChatMessagePromptTemplate.from_template(role='system', template=prompt_s1_sys)\n",
    "    prompt_s1_user = ChatMessagePromptTemplate.from_template(role='user', template=prompt_s1_user)\n",
    "    prompt_s1 = ChatPromptTemplate(messages = [prompt_s1_sys, prompt_s1_user]) # 传入 msg 列表 构成 多段输入\n",
    "    llm_s1 = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.5, request_timeout=120)\n",
    "    chain_s1 = LLMChain(llm=llm_s1, prompt=prompt_s1)\n",
    "    \n",
    "    async def async_chain_s1(item, citynumstr, target_city, loop_times=3):\n",
    "        cur_times = 0\n",
    "        while(cur_times < loop_times):\n",
    "            try:\n",
    "                arr_res_multi = await chain_s1.arun({'item':item, 'citynumstr':citynumstr, 'target_city':target_city})\n",
    "                return arr_res_multi\n",
    "            except:\n",
    "                cur_times += 1\n",
    "        return '' # 超过最大尝试次数后 返回 空字符串\n",
    "    \n",
    "    async def async_chain_s1_main(strings_list, target_city):\n",
    "        tasks = [async_chain_s1(item, citynumstr, target_city) for item, citynumstr in strings_list]\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        \n",
    "        for i, response in enumerate(responses):\n",
    "            prompt = f\"有些城市发生了疫情，城市封控前后14天的{idx_to_item[i]}类商品的销量（经过了归一化）如下。{strings_list[i][1]}。已知{target_city}和上述城市的销量变化相似，请分析{target_city}在封控之后14天内销量的可能变化趋势。给出分析和总结，格式为@分析：（分析内容）@总结：（总结内容）。总结部分仅给出上升下降趋势，幅度，时间，如何波动等销量变化信息，不要提及其他城市，尽量简洁清晰。\"\n",
    "            logging.info(f\"{cityidx}, {i} \\n{prompt} \\n\\n{response} \\n\")\n",
    "            response_dict[(cityidx, i)] = response\n",
    "            \n",
    "\n",
    "    citynumstr_list = []\n",
    "    for item in range(26):\n",
    "        cityidxlist = similarcity_dict[cityidx]\n",
    "        citynumlist = [f\"{idx_to_city[idx]}: 封控前单量：{[round(num, 4) for num in num_dict[(idx, item)][:14].numpy().tolist()]}，封控后单量：{[round(num, 4) for num in num_dict[(idx, item)][14:].numpy().tolist()]}\" for idx in cityidxlist]\n",
    "        citynumstr = \"。\".join(citynumlist)\n",
    "        citynumstr_list.append(citynumstr)\n",
    "    \n",
    "    await async_chain_s1_main(list(zip(item_list, citynumstr_list)), target_city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c572a629-4a03-4112-bc33-5901f522c705",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists('./llmlogs'):\n",
    "    os.makedirs('./llmlogs')\n",
    "# 获取根记录器\n",
    "logger = logging.getLogger()\n",
    "# 移除已有的处理器\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "# 配置日志记录器\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "logging.basicConfig(\n",
    "    filename=f'./llmlogs/response_dict_async.log',#_bs{batch_size}_epo{epochs}_{current_time}\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "response_dict = {}\n",
    "for cityidx in city_to_idx.values(): #[0,1]:# \n",
    "    target_city = idx_to_city[cityidx]\n",
    "    t1 = time.time()\n",
    "    loop = asyncio.get_event_loop()\n",
    "    loop.run_until_complete(async_LLM_similar(cityidx, [idx_to_item[idx] for idx in range(26)], target_city))\n",
    "    t2 = time.time()\n",
    "    print(cityidx, idx_to_city[cityidx], t2-t1)\n",
    "\n",
    "with open('./data/response_dict_async.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(response_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975e5ab9-9772-4954-a6db-9157ae666e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/response_dict_async.pkl', 'rb') as pickle_file:\n",
    "    response_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdf3891-72d4-4fa3-bcfd-128b894d88b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 异步调用丢失的值\n",
    "no_response = []\n",
    "for key, response in response_dict.items():\n",
    "    if response == \"\":\n",
    "        no_response.append(key)\n",
    "print(len(no_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec055e07-af29-4b1b-9c1e-4c765d287e9d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import time\n",
    "from transformers import logging as transformers_logging\n",
    "import warnings\n",
    "\n",
    "# 忽略所有警告\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# 设置transformers的日志级别为ERROR\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "if not os.path.exists('./llmlogs'):\n",
    "    os.makedirs('./llmlogs')\n",
    "# 获取根记录器\n",
    "logger = logging.getLogger()\n",
    "# 移除已有的处理器\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "# 配置日志记录器\n",
    "# current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M\")\n",
    "logging.basicConfig(\n",
    "    filename=f'./llmlogs/no_response_dict.log',#_bs{batch_size}_epo{epochs}_{current_time}\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "no_response_dict = {}\n",
    "\n",
    "for i, (cityidx, item) in enumerate(no_response):\n",
    "    t1 = time.time()\n",
    "    cityidxlist = similarcity_dict[cityidx]\n",
    "    citynumlist = [f\"{idx_to_city[idx]}: 封控前单量：{[round(num, 4) for num in num_dict[(idx, item)][:14].numpy().tolist()]}，封控后单量：{[round(num, 4) for num in num_dict[(idx, item)][14:].numpy().tolist()]}\" for idx in cityidxlist]\n",
    "    citynumstr = \"。\".join(citynumlist)\n",
    "\n",
    "    memory = ConversationBufferMemory()\n",
    "    conversation = ConversationChain(llm=chat_model, memory=memory)\n",
    "\n",
    "    prompt = f\"有些城市发生了疫情，城市封控前后14天的{idx_to_item[item]}类商品的销量（经过了归一化）如下。{citynumstr}。已知{idx_to_city[cityidx]}和上述城市的销量变化相似，请分析{idx_to_city[cityidx]}在封控之后14天内销量的可能变化趋势。给出分析和总结，格式为@分析：（分析内容）@总结：（总结内容）。总结部分仅给出上升下降趋势，幅度，时间，如何波动等销量变化信息，不要提及其他城市，尽量简洁清晰。\"\n",
    "    \n",
    "    response = conversation.run(input=prompt)\n",
    "    logging.info(f\"{cityidx}, {item} \\n{prompt} \\n\\n{response} \\n\")\n",
    "    no_response_dict[(cityidx, item)] = response\n",
    "\n",
    "    t2 = time.time()\n",
    "    print(i, cityidx, idx_to_city[cityidx], t2-t1)\n",
    "    if response == \"\":\n",
    "        print(\"!\"*50)\n",
    "\n",
    "with open('./data/no_response_dict.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(no_response_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc74e3c5-1669-405f-bdb9-9b6a50e8cd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/no_response_dict.pkl', 'rb') as pickle_file:\n",
    "    no_response_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ea240-b17b-4abf-86ba-2ca9e62950f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_response_dict = {}\n",
    "for key in response_dict:\n",
    "    all_response_dict[key] = no_response_dict[key] if key in no_response_dict else response_dict[key]\n",
    "with open('./data/all_response_dict.pkl', 'wb') as pickle_file:\n",
    "    pickle.dump(all_response_dict, pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d2a69b-409d-4c37-9f29-9c9dc7d6c97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/all_response_dict.pkl', 'rb') as pickle_file:\n",
    "    all_response_dict = pickle.load(pickle_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c10cda-a31b-402e-9880-2aca440dc1a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# embed_dict = {}\n",
    "embed_tensor = torch.zeros((337, 26, 768))\n",
    "\n",
    "keys = list(all_response_dict.keys())\n",
    "texts = list(all_response_dict.values())\n",
    "texts = [extract_summary(text) for text in texts]\n",
    "\n",
    "batch = 2048\n",
    "for i in range(0, len(texts), batch):\n",
    "    batch_keys = keys[i:min(i + batch, len(texts))]\n",
    "    batch_texts = texts[i:min(i + batch, len(texts))]\n",
    "    sentence_embeddings = text_embed(batch_texts).cpu()\n",
    "    # 更新嵌入字典\n",
    "    for key, embed in zip(batch_keys, sentence_embeddings):\n",
    "        # embed_dict[key] = embed\n",
    "        embed_tensor[key[0]][key[1]] = embed\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebe9aed-4c06-4889-a128-1dc85b69cea8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open('./data/embed_dict.pkl', 'wb') as pickle_file:\n",
    "#     pickle.dump(embed_dict, pickle_file)\n",
    "# with open('./data/embed_dict.pkl', 'rb') as pickle_file:\n",
    "#     embed_dict = pickle.load(pickle_file)\n",
    "torch.save(embed_tensor, './data/embed_tensor.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a9002-a31f-4a76-8f13-bf1b6b17a476",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "embed_tensor = torch.load('./data/embed_tensor.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb8cdbd-24b0-4baf-b2fe-ebc1884a772d",
   "metadata": {},
   "source": [
    "## case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650027d2-b30b-4879-bd4b-58a0ae231b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = 1\n",
    "city = 254\n",
    "\n",
    "cityidxlist = similarcity_dict[city]\n",
    "print(idx_to_city[city], idx_to_item[item], [idx_to_city[idx] for idx in cityidxlist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0347502a-24b3-425b-bce3-1a13d8898dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array([[round(num, 4) for num in num_dict[(idx, item)].numpy().tolist()] for idx in cityidxlist])\n",
    "tt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff6e7af-7936-4c64-96de-bd8a2e3757af",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[round(num, 4) for num in num_dict[(idx, item)].numpy().tolist()] for idx in [city]])\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666545ac-004a-4b34-84bc-bb5027f1bd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(sub_sequence):\n",
    "    min_val = np.min(sub_sequence[:14])\n",
    "    max_val = np.max(sub_sequence[:14])\n",
    "    # 避免除以零的情况\n",
    "    if max_val - min_val == 0:\n",
    "        return sub_sequence  # 如果所有值相同，返回原序列\n",
    "    return (sub_sequence - min_val) / (max_val - min_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76bd904-3753-4f98-86d0-007681bdb4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = np.array([min_max_normalize(ttt) for ttt in tt])\n",
    "data = min_max_normalize(data)\n",
    "tt.shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a111eaed-3621-4d77-b7d2-5c6d13b05f7a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def dtw_distance(sequence1, sequence2):\n",
    "    n = len(sequence1)\n",
    "    m = len(sequence2)\n",
    "    # 创建一个 (n+1) x (m+1) 的距离矩阵，初始化为无穷大\n",
    "    dtw_matrix = np.full((n + 1, m + 1), np.inf)\n",
    "    dtw_matrix[0, 0] = 0\n",
    "\n",
    "    # 填充 DTW 矩阵\n",
    "    for i in range(1, n + 1):\n",
    "        for j in range(1, m + 1):\n",
    "            cost = abs(sequence1[i - 1] - sequence2[j - 1])\n",
    "            # 选择最小的累积距离路径\n",
    "            dtw_matrix[i, j] = cost + min(\n",
    "                dtw_matrix[i - 1, j],    # 插入\n",
    "                dtw_matrix[i, j - 1],    # 删除\n",
    "                dtw_matrix[i - 1, j - 1] # 匹配\n",
    "            )\n",
    "\n",
    "    # 返回 DTW 距离\n",
    "    return dtw_matrix[n, m]\n",
    "\n",
    "# # 示例序列\n",
    "# sequence_a = np.random.rand(28)\n",
    "# sequence_b = np.random.rand(28)\n",
    "\n",
    "# # 计算 DTW 距离\n",
    "# distance = dtw_distance(sequence_a, sequence_b)\n",
    "# print(\"DTW distance:\", distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e6fe97-a13c-4545-bb56-f484b3312c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算每个序列与目标序列的 DTW 距离\n",
    "distances = []\n",
    "for i, sequence in enumerate(tt):\n",
    "    distance = dtw_distance(sequence, data[0])\n",
    "    distances.append((distance, i))\n",
    "\n",
    "# 按距离排序，找出最小的 5 个距离对应的序列索引\n",
    "distances.sort(key=lambda x: x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bf585-3f70-4194-a23a-88213ef3d1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5idx = [idx for _, idx in distances[:5]]\n",
    "bottom5idx = [idx for _, idx in distances[-5:]]\n",
    "top5idx, bottom5idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66984a4e-9250-4139-9da6-e416f7c656ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建图形和子图\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(6, 5))\n",
    "axes = axes.flatten()  # 将子图对象展平成一维数组，方便迭代\n",
    "\n",
    "\n",
    "ax = axes[0]\n",
    "# 绘制前14天\n",
    "ax.plot(range(15), data[0, :15], color='blue')\n",
    "# 绘制后14天\n",
    "ax.plot(range(14, 28), data[0, 14:], color='red')\n",
    "# 添加标题和图例\n",
    "ax.set_title(f'{0}')\n",
    "\n",
    "# 可视化每个时间序列\n",
    "for i, idx in enumerate(top5idx):\n",
    "    ax = axes[i+1]\n",
    "    time_series = tt[idx]\n",
    "    \n",
    "    # 绘制前14天\n",
    "    ax.plot(range(15), time_series[:15], color='blue')\n",
    "    \n",
    "    # 绘制后14天\n",
    "    ax.plot(range(14, 28), time_series[14:], color='red')\n",
    "    \n",
    "    # 添加标题和图例\n",
    "    ax.set_title(f'{i+1}')\n",
    "    #ax.legend()\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293784a7-f401-4d61-9e79-32cbe9e6de81",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 创建图形和子图\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(6, 5))\n",
    "axes = axes.flatten()  # 将子图对象展平成一维数组，方便迭代\n",
    "\n",
    "\n",
    "ax = axes[0]\n",
    "# 绘制前14天\n",
    "ax.plot(range(15), data[0, :15], color='blue')\n",
    "# 绘制后14天\n",
    "ax.plot(range(14, 28), data[0, 14:], color='red')\n",
    "# 添加标题和图例\n",
    "ax.set_title(f'{0}')\n",
    "\n",
    "# 可视化每个时间序列\n",
    "for i, idx in enumerate(bottom5idx):\n",
    "    ax = axes[i+1]\n",
    "    time_series = tt[idx]\n",
    "    \n",
    "    # 绘制前14天\n",
    "    ax.plot(range(15), time_series[:15], color='blue')\n",
    "    \n",
    "    # 绘制后14天\n",
    "    ax.plot(range(14, 28), time_series[14:], color='red')\n",
    "    \n",
    "    # 添加标题和图例\n",
    "    ax.set_title(f'{i+1}')\n",
    "    #ax.legend()\n",
    "\n",
    "# 调整布局\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce819f7-2e4d-4b5d-94e9-403ee7a2cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt[top5idx].shape, tt[bottom5idx].shape, data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caa02ee-445c-48ea-9e79-32973a472a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "top5city = [idx_to_city[idx] for idx in [cityidxlist[id] for id in top5idx]]\n",
    "bottom5city = [idx_to_city[idx] for idx in [cityidxlist[id] for id in bottom5idx]]\n",
    "top5city, bottom5city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de39a2fa-48ed-43c8-94db-2696544047ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存多个数组到一个 .npz 文件\n",
    "np.savez(f'./data/case_city{city}_item{item}.npz', top5city=tt[top5idx], othercity=tt[bottom5idx], targetcity=data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510fe8f9-af76-45ca-b852-12569d256a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载 .npz 文件\n",
    "with np.load('./data/case_city254_item1.npz') as data:\n",
    "    top5city = data['top5city'] # 5*28\n",
    "    othercity = data['othercity'] # 5*28\n",
    "    targetcity = data['targetcity'] # 28\n",
    "print(top5city.shape, othercity.shape, targetcity.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b026e766-a60b-4565-930e-8fba98fc0763",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (PySpark)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
